package utils

import (
	"errors"
	"sync"
)

var (
	dfaInstance map[string]*DFAInstance
	mu          sync.RWMutex
)

type DFAInstance struct {
	DFA      *DFA
	BuffSize int
}

// GetDFA returns the singleton instance of DFA
func GetDFA(kbID string) *DFAInstance {
	mu.RLock()
	defer mu.RUnlock()
	return dfaInstance[kbID]
}

// InitDFA Initialize a new DFA. --> this func used by pro
func InitDFA(kbID string, words []string) {
	mu.Lock()
	defer mu.Unlock()
	newDFA := &DFA{
		Root: NewTrieNode(),
	}
	var BuffSize int // é»˜è®¤ä¸º0
	for _, word := range words {
		newDFA.AddWord(word)
		if BuffSize < len([]rune(word)) {
			BuffSize = len([]rune(word))
		}
	}
	if dfaInstance == nil {
		dfaInstance = make(map[string]*DFAInstance)
	}
	dfaInstance[kbID] = &DFAInstance{
		DFA:      newDFA,
		BuffSize: BuffSize,
	}
}

// TrieNode Define the nodes of DFA
type TrieNode struct {
	Children map[rune]*TrieNode
	IsEnd    bool
}

// NewTrieNode Create a new Trie node
func NewTrieNode() *TrieNode {
	return &TrieNode{
		Children: make(map[rune]*TrieNode),
		IsEnd:    false,
	}
}

// DFA The structure contains the root node of the DFA
type DFA struct {
	Root *TrieNode
}

// AddWord Add sensitive words to DFA
func (d *DFA) AddWord(word string) {
	node := d.Root
	for _, char := range word {
		if _, exists := node.Children[char]; !exists {
			node.Children[char] = NewTrieNode()
		}
		node = node.Children[char]
	}
	node.IsEnd = true
}

// UpdateOldWord update old word
func (d *DFA) UpdateOldWord(oldWord, newWord string) {
	d.DeleteWord(oldWord)
	d.AddWord(newWord)
}

// DeleteWord delete word
func (d *DFA) DeleteWord(word string) bool {
	result := []rune(word)
	// è¾…åŠ©å‡½æ•°ç”¨äºŽé€’å½’åˆ é™¤èŠ‚ç‚¹
	var deleteNode func(node *TrieNode, index int) bool
	deleteNode = func(node *TrieNode, index int) bool {
		if index == len(result) {
			// å¦‚æžœè¯¥è¯ä¸å­˜åœ¨ï¼Œç›´æŽ¥è¿”å›ž
			if !node.IsEnd {
				return false
			}
			// æ¸…é™¤è¯¥è¯çš„ç»“æŸæ ‡è®°
			node.IsEnd = false
			// å¦‚æžœè¯¥èŠ‚ç‚¹æ²¡æœ‰å­èŠ‚ç‚¹ï¼Œå¯ä»¥åˆ é™¤
			return len(node.Children) == 0
		}

		char := result[index]
		child, exists := node.Children[char]
		if !exists {
			return false // å¦‚æžœè·¯å¾„ä¸å­˜åœ¨ï¼Œåˆ™ä¸åšä»»ä½•æ“ä½œ
		}

		// é€’å½’åˆ é™¤å­èŠ‚ç‚¹
		shouldDeleteChild := deleteNode(child, index+1)
		if shouldDeleteChild {
			// åˆ é™¤å½“å‰èŠ‚ç‚¹çš„å­èŠ‚ç‚¹
			delete(node.Children, char)
			// å¦‚æžœå½“å‰èŠ‚ç‚¹æ²¡æœ‰å…¶ä»–å­èŠ‚ç‚¹ä¸”ä¸æ˜¯è¯å°¾èŠ‚ç‚¹ï¼Œè¿”å›ž true
			return len(node.Children) == 0 && !node.IsEnd
		}
		return false
	}

	// è°ƒç”¨é€’å½’å‡½æ•°åˆ é™¤æŒ‡å®šçš„è¯
	return deleteNode(d.Root, 0)
}

// DeleteWordBatch delete word batch
func (d *DFA) DeleteWordBatch(words []string) {
	wg := sync.WaitGroup{}
	for _, word := range words {
		wg.Add(1)
		go func() {
			d.DeleteWord(word)
			wg.Done()
		}()
	}
	wg.Wait()
}

// Filter the input text and replace sensitive words
func (d *DFA) Filter(text string) string {
	result := []rune(text)             // è½¬åŒ–ä¸ºrune
	for i := 0; i < len(result); i++ { // å¤–å±‚å¾ªçŽ¯ï¼ŒéåŽ†æ¯ä¸ªå­—ç¬¦ä½œä¸ºèµ·å§‹ç‚¹
		node := d.Root
		j := i
		for j < len(result) { // å†…å±‚å¾ªçŽ¯ï¼Œå°è¯•åŒ¹é…æ•æ„Ÿè¯
			if nextNode, exists := node.Children[result[j]]; exists { // å¦‚æžœå½“å‰å­—ç¬¦åœ¨å­èŠ‚ç‚¹ä¸­å­˜åœ¨
				node = nextNode // ä¸‹ç§»
				if node.IsEnd { // æ˜¯å¦ä¸ºç»“å°¾ï¼Œå³åŒ¹é…åˆ°æ•æ„Ÿè¯ï¼Œæ›¿æ¢ä¸º*
					for k := i; k <= j; k++ {
						result[k] = 'ðŸš«'
					}
				}
				j++ // next char
			} else {
				break
			}
		}
	}
	return string(result)
}

// Check  if the input text contains sensitive words
func (d *DFA) Check(text string) error {
	result := []rune(text)
	for i := 0; i < len(result); {
		node := d.Root
		start := i
		matched := false
		for j := i; j < len(result); j++ {
			char := result[j]
			if nextNode, exists := node.Children[char]; exists {
				node = nextNode
				if node.IsEnd {
					return errors.New("åŒ…å«æ•æ„Ÿè¯: " + string(result[start:j+1]))
				}
			} else {
				break
			}
		}
		if !matched {
			i++
		}
	}
	return nil
}
